{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/amy/work/RIT/TDess/DSCI-601-Amy/Data/Combined/combined_AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>VOL_CHANGE</th>\n",
       "      <th>BA_SPREAD</th>\n",
       "      <th>ILLIQUIDITY</th>\n",
       "      <th>sprtrn</th>\n",
       "      <th>TURNOVER</th>\n",
       "      <th>DJI_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/1992</td>\n",
       "      <td>0.055432</td>\n",
       "      <td>0.717745</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>4.510000e-10</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>17.419850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/3/1992</td>\n",
       "      <td>-0.008403</td>\n",
       "      <td>-0.172890</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>-8.340000e-11</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>14.408127</td>\n",
       "      <td>0.009173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/6/1992</td>\n",
       "      <td>-0.016949</td>\n",
       "      <td>-0.399632</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>-2.850000e-10</td>\n",
       "      <td>-0.003291</td>\n",
       "      <td>8.650181</td>\n",
       "      <td>-0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/7/1992</td>\n",
       "      <td>0.019397</td>\n",
       "      <td>0.237283</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>2.590000e-10</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>10.702726</td>\n",
       "      <td>0.001469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/8/1992</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.645321</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>1.840000e-10</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>17.609419</td>\n",
       "      <td>-0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804</th>\n",
       "      <td>12/23/2022</td>\n",
       "      <td>-0.002798</td>\n",
       "      <td>-0.181476</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-3.330000e-13</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>4.008909</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7805</th>\n",
       "      <td>12/27/2022</td>\n",
       "      <td>-0.013878</td>\n",
       "      <td>0.081093</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-1.550000e-12</td>\n",
       "      <td>-0.004050</td>\n",
       "      <td>4.334004</td>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>12/28/2022</td>\n",
       "      <td>-0.030685</td>\n",
       "      <td>0.238299</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-2.850000e-12</td>\n",
       "      <td>-0.012021</td>\n",
       "      <td>5.366792</td>\n",
       "      <td>-0.011006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807</th>\n",
       "      <td>12/29/2022</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>-0.115337</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>2.890000e-12</td>\n",
       "      <td>0.017461</td>\n",
       "      <td>4.747802</td>\n",
       "      <td>0.010497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7808</th>\n",
       "      <td>12/30/2022</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.019326</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>2.470000e-13</td>\n",
       "      <td>-0.002541</td>\n",
       "      <td>4.859630</td>\n",
       "      <td>-0.002214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7809 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       RET  VOL_CHANGE  BA_SPREAD   ILLIQUIDITY    sprtrn  \\\n",
       "0       1/2/1992  0.055432    0.717745   0.008403  4.510000e-10  0.000408   \n",
       "1       1/3/1992 -0.008403   -0.172890   0.004237 -8.340000e-11  0.004985   \n",
       "2       1/6/1992 -0.016949   -0.399632   0.004310 -2.850000e-10 -0.003291   \n",
       "3       1/7/1992  0.019397    0.237283   0.004228  2.590000e-10 -0.001340   \n",
       "4       1/8/1992  0.023256    0.645321   0.004132  1.840000e-10  0.001677   \n",
       "...          ...       ...         ...        ...           ...       ...   \n",
       "7804  12/23/2022 -0.002798   -0.181476   0.000076 -3.330000e-13  0.005868   \n",
       "7805  12/27/2022 -0.013878    0.081093   0.000231 -1.550000e-12 -0.004050   \n",
       "7806  12/28/2022 -0.030685    0.238299   0.000079 -2.850000e-12 -0.012021   \n",
       "7807  12/29/2022  0.028324   -0.115337   0.000231  2.890000e-12  0.017461   \n",
       "7808  12/30/2022  0.002469    0.019326   0.000231  2.470000e-13 -0.002541   \n",
       "\n",
       "       TURNOVER  DJI_Return  \n",
       "0     17.419850    0.000000  \n",
       "1     14.408127    0.009173  \n",
       "2      8.650181   -0.000437  \n",
       "3     10.702726    0.001469  \n",
       "4     17.609419   -0.000281  \n",
       "...         ...         ...  \n",
       "7804   4.008909    0.005342  \n",
       "7805   4.334004    0.001133  \n",
       "7806   5.366792   -0.011006  \n",
       "7807   4.747802    0.010497  \n",
       "7808   4.859630   -0.002214  \n",
       "\n",
       "[7809 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished.\n",
      "Final balance: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, n_actions, n_states, learning_rate=0.1, discount_factor=0.99, epsilon=0.1):\n",
    "        self.q_table = np.zeros((n_states, n_actions))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.n_actions = n_actions\n",
    "        self.n_states = n_states\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            return np.random.choice(self.n_actions)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])\n",
    "\n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state, best_next_action]\n",
    "        td_error = td_target - self.q_table[state, action]\n",
    "        self.q_table[state, action] += self.learning_rate * td_error\n",
    "\n",
    "class StockTradingEnvironment:\n",
    "    def __init__(self, data, initial_balance=1000):\n",
    "        self.data = data\n",
    "        self.current_step = 0\n",
    "        self.balance = initial_balance\n",
    "        self.shares_held = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        current_price = 1  # Assuming price is normalized for simplicity\n",
    "        next_price = 1  # Static price for simplicity\n",
    "        reward = 0\n",
    "        \n",
    "        # Actions: 0 = Buy, 1 = Sell, 2 = Hold\n",
    "        if action == 0:  # Buy\n",
    "            if self.balance >= current_price:\n",
    "                self.shares_held += 1\n",
    "                self.balance -= current_price\n",
    "                reward = self.data.iloc[self.current_step]['RET']\n",
    "        elif action == 1:  # Sell\n",
    "            if self.shares_held > 0:\n",
    "                self.shares_held -= 1\n",
    "                self.balance += next_price\n",
    "                reward = -self.data.iloc[self.current_step]['RET']\n",
    "\n",
    "        self.current_step += 1\n",
    "        next_state = self.get_state(self.current_step)\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        return next_state, reward, done, self.balance\n",
    "\n",
    "    def get_state(self, step):\n",
    "        row = self.data.iloc[step]\n",
    "        features = ['VOL_CHANGE', 'BA_SPREAD', 'ILLIQUIDITY', 'sprtrn', 'TURNOVER', 'DJI_Return']\n",
    "        state = 0\n",
    "        for i, feature in enumerate(features):\n",
    "            state += (row[feature] > self.data[feature].median()) * (2 ** i)\n",
    "        return state\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.balance = 1000  # Reset balance\n",
    "        self.shares_held = 0\n",
    "        return self.get_state(self.current_step)\n",
    "\n",
    "# Load your dataset\n",
    "data = df  # Provide your DataFrame here\n",
    "\n",
    "# Initialize the agent and environment\n",
    "env = StockTradingEnvironment(data)\n",
    "n_states = 2 ** len(['VOL_CHANGE', 'BA_SPREAD', 'ILLIQUIDITY', 'sprtrn', 'TURNOVER', 'DJI_Return'])  # Assuming binary state for simplicity\n",
    "agent = QLearningAgent(n_actions=3, n_states=n_states)\n",
    "\n",
    "# Run simulation\n",
    "state = env.reset()\n",
    "done = False\n",
    "total_balance = []\n",
    "while not done:\n",
    "    action = agent.choose_action(state)\n",
    "    next_state, reward, done, balance = env.step(action)\n",
    "    agent.update_q_table(state, action, reward, next_state)\n",
    "    state = next_state\n",
    "    total_balance.append(balance)\n",
    "\n",
    "# Analyze performance\n",
    "print(\"Simulation finished.\")\n",
    "print(\"Final balance:\", total_balance[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from gym import spaces\n",
    "\n",
    "class StockTradingEnv(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df):\n",
    "        super(StockTradingEnv, self).__init__()\n",
    "\n",
    "        self.df = df\n",
    "        self.reward_range = (0, max(df['RET']))\n",
    "        \n",
    "        # Actions of the format Buy x%, Sell x%, Hold, etc.\n",
    "        self.action_space = spaces.Box(low=np.array([0, 0]), high=np.array([3, 1]), dtype=np.float16)\n",
    "        \n",
    "        # Prices contains the OHLC values for the last five prices\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(6,), dtype=np.float16)\n",
    "        \n",
    "    def _next_observation(self):\n",
    "        # Get the data points for the last 5 days and scale to between 0-1\n",
    "        frame = np.array([\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'RET'].values / max(self.df['RET']),\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'VOL_CHANGE'].values / max(self.df['VOL_CHANGE']),\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'BA_SPREAD'].values / max(self.df['BA_SPREAD']),\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'ILLIQUIDITY'].values / max(self.df['ILLIQUIDITY']),\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'sprtrn'].values / max(self.df['sprtrn']),\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'TURNOVER'].values / max(self.df['TURNOVER']),\n",
    "        ]).reshape(6,)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Not executing properly\n",
    "        # Execute one time step within the environment\n",
    "        self.current_step += 1\n",
    "        \n",
    "        if self.current_step > len(self.df.loc[:, 'RET'].values) - 6:\n",
    "            self.current_step = 0\n",
    "        \n",
    "        delay_modifier = (self.current_step / max(self.df.index))\n",
    "\n",
    "        reward = self.df.loc[self.current_step, 'RET'] * delay_modifier\n",
    "        done = self.df.loc[self.current_step, 'RET'] < 0\n",
    "        \n",
    "        obs = self._next_observation()\n",
    "        \n",
    "        return obs, reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset the state of the environment to an initial state\n",
    "        self.current_step = 0\n",
    "        \n",
    "        return self._next_observation()\n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        # Render the environment to the screen\n",
    "        profit = self.df.loc[self.current_step, 'RET']\n",
    "\n",
    "        print(f'Step: {self.current_step}')\n",
    "        print(f'Profit: {profit}')\n",
    "        \n",
    "# load data\n",
    "env = StockTradingEnv(df)\n",
    "\n",
    "# Check if the environment follows gym interface\n",
    "check_env(env, warn=True)\n",
    "\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
